{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.readfile import ReadFile as rf\n",
    "from lib.handle_null_values import handle_null_values as null\n",
    "from lib.datetime_formatting import DatetimeFormatting as dfmt\n",
    "from lib.split_time_variable import split_time_variable as split_t\n",
    "from lib.correct_variable_types import correct_variable_types as vartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read the file\"\"\"\n",
    "\n",
    "r= rf()\n",
    "df= r.read(address=\"lib/data/2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove column with null values\"\"\"\n",
    "\n",
    "n= null()\n",
    "variables= n.delete_var_with_null_more_than(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"drop unwanted variables for now\"\"\"\n",
    "\n",
    "df2= df.drop(*variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"select important variables\"\"\" \n",
    "\n",
    "important_variables=['year_built', 'bedroom_count', 'bathroom_count','lot_size', 'area', 'bike_score', 'city_name', 'community_name', 'covered_parking', 'created_date', 'exterior', 'energy_source','fireplaces_count', 'floor_covering', 'garage','heating_cooling','latitude','longitude', 'property_type', 'roof', 'school_district',  'sewer', 'sold_date', 'sold_price','unfinished_sq_foot', 'topography', 'transit_score', 'was_flip', 'year_built', 'zip_code', 'county' ]\n",
    "\n",
    "    \n",
    "important_variables= list(set(important_variables))\n",
    "df3= df2.select(*important_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"concatenate all files\"\"\"\n",
    "\n",
    "files= [\"09\"]\n",
    "for f_no in range(10, 20):\n",
    "    files.append(f_no)    \n",
    "    \n",
    "    df4= r.read(address=\"lib/data/20\"+str(10)+\".csv\")\n",
    "    df4= df4.select(*important_variables)\n",
    "    df3 = df3.union(df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"filter one county from the dataset\"\"\"\n",
    "\n",
    "df5= df3.filter( df3[\"county\"].isin([\"King\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"correct time format\"\"\"\n",
    "\n",
    "f= split_t()\n",
    "\n",
    "#Assuming time variable is in timestamp type\n",
    "df6= f.run(df5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Correct variable types\"\"\"\n",
    "\n",
    "v= vartype()\n",
    "\n",
    "df7= v.run(df6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=df6.limit(500).toPandas()\n",
    "\n",
    "numeric_columns= []\n",
    "columns2= df6.columns # only take string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in columns2:\n",
    "    counter= 0\n",
    "    e=[]\n",
    "    float_values= []\n",
    "    print(c)\n",
    "    for i in range(500):\n",
    "        try:\n",
    "            v= float(p[c][i])\n",
    "            counter= counter+1\n",
    "            float_values.append(v)\n",
    "        except:\n",
    "            print(str(p[c][i]))\n",
    "            e.append(str(p[c][i]))\n",
    "\n",
    "    if len(e)==0:\n",
    "        numeric_columns.append(c)  \n",
    "    elif len(set(float_values))<5: \n",
    "        if len(set(e))<=1 and len(set(float_values))!=0:\n",
    "            numeric_columns.append(c)  \n",
    "    elif len(float_values)/500*100 > 95:\n",
    "            numeric_columns.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_numeric_variables_saved_as_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f217f63a730a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_numeric_variables_saved_as_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'find_numeric_variables_saved_as_string' is not defined"
     ]
    }
   ],
   "source": [
    "var=find_numeric_variables_saved_as_string(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"treat duplications\"\"\"\n",
    "df6.select('year_built').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the deep learning model and put that on the training\n",
    "\n",
    "def var_types(df7):\n",
    "    categorical_variables= []\n",
    "    numerical_variables=[]\n",
    "    for dt in df7.dtypes:\n",
    "        if dt[1]==\"string\":\n",
    "            categorical_variables.append(dt[0])\n",
    "        else:\n",
    "            numerical_variables.append(dt[0])\n",
    "    return categorical_variables, numerical_variables\n",
    "        \n",
    "categorical_variables, numerical_variables= var_types(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"treat null values using deep learning\"\"\"\n",
    "\n",
    "# add an ID in the dataset\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from math import *\n",
    "\n",
    "\n",
    "spark_context = SparkContext.getOrCreate()\n",
    "spark = SparkSession(spark_context)\n",
    "\n",
    "windowSpec = W.orderBy(df7.columns[0])\n",
    "df7= df7.withColumn(\"id\", F.row_number().over(windowSpec))\n",
    "df8= df7.createOrReplaceTempView(\"customer\")\n",
    "\n",
    "#use this ID to filter the data and get results.\n",
    "base_query = \"SELECT * FROM customer where \"\n",
    "total_rows= df7.count()\n",
    "each_page= 500\n",
    "total_pages= ceil(total_rows/each_page)\n",
    "\n",
    "for p in range(total_pages):\n",
    "    query= base_query + \"id > \" + str(each_page*p) + \" and id< \" + str(each_page*(p+1))\n",
    "    df_spark= spark.sql(query)\n",
    "\n",
    "    df_pandas= df_spark.toPandas()\n",
    "    \n",
    "    #pass this through all the models in the same order and run it.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
