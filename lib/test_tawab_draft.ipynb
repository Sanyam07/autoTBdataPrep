{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.readfile import ReadFile as rf\n",
    "from lib.handle_null_values import handle_null_values as null\n",
    "from lib.datetime_formatting import DatetimeFormatting_v2 as dfmt\n",
    "from lib.duplication import Duplication as dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10-07 10:29:23] p9280 {D:\\Projects\\data-science\\open source projects\\mltrons_auto_clean\\lib\\read_file_from_local.py:47} ERROR - 'Path does not exist: file:/D:/Projects/data-science/open source projects/mltrons_auto_clean/lib/vinod/2009.csv;'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read the file\"\"\"\n",
    "\n",
    "r= rf()\n",
    "df= r.read(address=\"lib/vinod/2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10-07 10:29:23] p9280 {D:\\Projects\\data-science\\open source projects\\mltrons_auto_clean\\lib\\duplication.py:136} ERROR - 'dict' object has no attribute 'select'\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Fetch automatically columns containing urd\"\"\"\n",
    "col_list = dup().fetch_columns_containing_url(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" currently no columns containing url\"\"\"\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10-07 10:29:23] p9280 {D:\\Projects\\data-science\\open source projects\\mltrons_auto_clean\\lib\\duplication.py:81} ERROR - 'NoneType' object is not iterable\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'limit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5501156e96ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"pass the list of urls to remove duplicates url\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mres_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_duplicate_urls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mres_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m### currently there are no url columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'limit'"
     ]
    }
   ],
   "source": [
    "\"\"\"pass the list of urls to remove duplicates url\"\"\"\n",
    "res_df = dup().remove_duplicate_urls(df,col_list,base_url='')\n",
    "res_df.limit(100).toPandas()\n",
    "\n",
    "### currently there are no url columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Remove all the columns which contains nan exceeding the threshold \"\"\"\n",
    "# threshold is considered as percent\n",
    "print(\"total columns\",len(df.columns))\n",
    "res_df = dup().remove_columns_containing_all_nan_values(df,threshold=75)\n",
    "print(\"only valid columns\",len(res_df.columns))\n",
    "print(\"columns contains null more than 75pct\",len(df.columns)-len(res_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" remove columns which contains same value in all rows \"\"\"\n",
    "print(\"total columns\",len(df.columns))\n",
    "res_df = dup().remove_columns_contains_same_value(df)\n",
    "print(\"only valid columns\",len(res_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" converting file into chunks\n",
    "    every chunk contains 100 rows\n",
    "    currenlty only lenght of each chunk is printed\n",
    "    but we can call any function inside the functtion\n",
    "\"\"\"\n",
    "dup().converting_file_into_chunks(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" fetch columns containing date time\"\"\"\n",
    "date_list = dfmt().fetch_columns_containing_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" converting all datetime format in a standard format \"\"\"\n",
    "res_df=dfmt().date_cleaning(df[date_list], date_list)\n",
    "res_df.limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
